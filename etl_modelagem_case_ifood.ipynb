{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c20ff1e5-095b-4029-968c-427910746a53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ETL: CRM Ifood - Bases de Disparos de Comunicações para clientes\n",
    "\n",
    "Esse notebook realiza as operações de ETL das bases de disparos de CRM, assim como outras dimensões necessárias para análises complementares.\n",
    "\n",
    "Os dados foram organizados no estilo medalhão (bronze, silver e gold):\n",
    "\n",
    "- Bronze: Tabelas cruas, assim como foram disponibilizadas via .csv\n",
    "- Silver: Tratamentos e padronizações realizadas. Aqui as tabelas já estão no formato Dimensional\n",
    "- Gold: Tabelas já consolidadas e agrupadas, prontas para serem usadas em Dashboards e outras análises.\n",
    "\n",
    "obs: Os arquivos .csv devem ser armazenados nas pastas correspondentes na camada bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcede90f-79f0-4caf-a9c3-ddc1886b4534",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Criação das Camadas"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.empty-table+json": {
       "directive_name": "NoDirective"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Cria os schemas:\n",
    "CREATE SCHEMA IF NOT EXISTS workspace.ifood_bronze\n",
    "COMMENT 'Camada Bronze - dados brutos do case iFood';\n",
    "\n",
    "CREATE SCHEMA IF NOT EXISTS workspace.ifood_silver\n",
    "COMMENT 'Camada Silver - dados limpos e padronizados';\n",
    "\n",
    "CREATE SCHEMA IF NOT EXISTS workspace.ifood_gold\n",
    "COMMENT 'Camada Gold - dados analíticos e agregados';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "411c8388-6c3b-4538-a851-ce82f586ddbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Os arquivos .csv devem ser armazenados nos diretórios correspondentes criados nesse bloco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb864369-10b9-4b3a-821c-51b2bb2eaf75",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Criação de pasta para armazenar as origens"
    }
   },
   "outputs": [],
   "source": [
    "# Cria o volume 'origens'\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    CREATE VOLUME IF NOT EXISTS workspace.ifood_bronze.origens\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Cria subfolders para cada arquivos recebido\n",
    "base_path = \"/Volumes/workspace/ifood_bronze/origens/\"\n",
    "\n",
    "folders = [\n",
    "    \"communications_base\",\n",
    "    \"merchant_info\",\n",
    "    \"cluster_merchant_history\",\n",
    "    \"conversion_base\"\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    path = f\"{base_path}{folder}\"\n",
    "    dbutils.fs.mkdirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79191603-b0ae-4351-b46f-1e502b4e54aa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Parâmetros"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Importando bibliotecas\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import when, col, lit\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, IntegerType, BooleanType, DateType, TimestampType, LongType\n",
    ")\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ETL_CRM_iFood\").getOrCreate()\n",
    "\n",
    "# Funções:\n",
    "\n",
    "# Helper para converter strings/bools para int (booleano) (tratando 'true','1','yes','t', etc.)\n",
    "def str_to_int_expr(col):\n",
    "    return (\n",
    "        F.when(F.lower(F.trim(F.col(col))).isin('true','1','t','yes','y'), F.lit(1))\n",
    "         .when(F.lower(F.trim(F.col(col))).isin('false','0','f','no','n'), F.lit(0))\n",
    "         .otherwise(F.lit(None))\n",
    "    )\n",
    "\n",
    "\n",
    "# Função para tratar nulos: transforma 'null' em null\n",
    "def normalize_nulls(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Substitui valores textuais como 'null', 'none', 'nan', 'na', 'undefined', etc. por null real.\n",
    "    Só aplica em colunas StringType.\n",
    "    \"\"\"\n",
    "    null_equivalents = [\"null\", \"none\", \"nan\", \"na\", \"undefined\", \"n/a\", \"\"]\n",
    "    df_out = df\n",
    "    for field in df.schema.fields:\n",
    "        if isinstance(field.dataType, StringType):\n",
    "            df_out = df_out.withColumn(\n",
    "                field.name,\n",
    "                F.when(F.lower(F.trim(F.col(field.name))).isin(null_equivalents), F.lit(None))\n",
    "                 .otherwise(F.col(field.name))\n",
    "            )\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb1de05c-9989-4f16-a194-413a2d8da4f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Camada Bronze:\n",
    "\n",
    "Dados Brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e3b8f69-0b4e-4ade-8401-4e85269fd537",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Importando as tabelas na camada bronze"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Fazer upload dos arquivos nos diretórios correspondentes\n",
    "\n",
    "\n",
    "# communications_base\n",
    "# Carregar dados\n",
    "comm = spark.read.option(\"header\", True).csv(\"/Volumes/workspace/ifood_bronze/origens/communications_base/communications_base_*.csv\")\n",
    "\n",
    "# Salvar como Delta Table\n",
    "comm.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"ifood_bronze.communications_base\")\n",
    "\n",
    "\n",
    "# cluster_merchant_history\n",
    "# Carregar dados\n",
    "comm = spark.read.option(\"header\", True).csv(\"/Volumes/workspace/ifood_bronze/origens/cluster_merchant_history/cluster_merchant_history_*.csv\")\n",
    "\n",
    "# Salvar como Delta Table\n",
    "comm.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"ifood_bronze.cluster_merchant_history\")\n",
    "\n",
    "\n",
    "# merchant_info\n",
    "# Carregar dados\n",
    "comm = spark.read.option(\"header\", True).csv(\"/Volumes/workspace/ifood_bronze/origens/merchant_info/merchant_info_*.csv\")\n",
    "\n",
    "# Salvar como Delta Table\n",
    "comm.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"ifood_bronze.merchant_info\")\n",
    "\n",
    "\n",
    "# conversion_base\n",
    "# Carregar dados\n",
    "comm = spark.read.option(\"header\", True).csv(\"/Volumes/workspace/ifood_bronze/origens/conversion_base/conversion_base_*.csv\")\n",
    "\n",
    "# Salvar como Delta Table\n",
    "comm.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"ifood_bronze.conversion_base\")\n",
    "\n",
    "# %sql\n",
    "# select * from ifood_bronze.communications_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a803cc4-f572-424c-9a85-dd7da2f3c08c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Camada Silver\n",
    "\n",
    "Criação das Fatos e Dimensões (vide diagrama em anexo)\n",
    "\n",
    "OBS: Comentar os blocos de criação após a primeira criação de cada base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d089761f-24b2-4e48-b1d6-5ba9214b4fde",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TbDimMerchant"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criação da TbDimMerchant\n",
    "\n",
    "# leitura da tabela bronze\n",
    "df_merchant_bronze = spark.read.table(\"workspace.ifood_bronze.merchant_info\")\n",
    "\n",
    "# normalizações + casts\n",
    "df_dim_merchant = (\n",
    "    df_merchant_bronze\n",
    "    .select(\n",
    "        F.col(\"merchant_id\").cast(StringType()).alias(\"IdMerchant\"),\n",
    "        F.col(\"contact_key_id\").cast(StringType()).alias(\"IdSubscriber\"),\n",
    "        F.col(\"performance_classification3\").cast(StringType()).alias(\"DsPerformanceClass\"),\n",
    "        F.col(\"contract_mode\").cast(StringType()).alias(\"DsModoContrato\"),\n",
    "        F.col(\"status_saturacao\").cast(StringType()).alias(\"StSaturacao\"),\n",
    "        str_to_int_expr(\"top_restaurants\").alias(\"FlTopRestaurantes\"),\n",
    "        F.col(\"dish_type\").cast(StringType()).alias(\"DsTipoComida\"),\n",
    "        F.col(\"state\").cast(StringType()).alias(\"DsEstado\"),\n",
    "        F.col(\"city\").cast(StringType()).alias(\"DsCidade\"),\n",
    "        F.col(\"merchant_city_maturity\").cast(StringType()).alias(\"DsMaturidadeMercadoCidade\"),\n",
    "        F.current_timestamp().alias(\"TsInclusao\")\n",
    "    )\n",
    "    .dropDuplicates([\"IdMerchant\"])\n",
    ")\n",
    "\n",
    "# aplica a limpeza de nulos textuais\n",
    "df_dim_merchant = normalize_nulls(df_dim_merchant)\n",
    "\n",
    "# Faz o merge: cria a tabela se não existir, ou atualiza se existir\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# Depois que a tabela for criada é só comentar esse bloco\n",
    "# Cria como Delta na camada Silver\n",
    "df_dim_merchant.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"workspace.ifood_silver.TbDimMerchant\")\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Referência à tabela Silver\n",
    "delta_table = DeltaTable.forName(spark, \"workspace.ifood_silver.TbDimMerchant\")\n",
    "\n",
    "# Merge dos dados novos\n",
    "(delta_table.alias(\"t\")\n",
    " .merge(\n",
    "     df_dim_merchant.alias(\"s\"),\n",
    "     \"t.IdMerchant = s.IdMerchant\"\n",
    " )\n",
    " .whenMatchedUpdate(set={\n",
    "    \"IdSubscriber\": \"s.IdSubscriber\",\n",
    "    \"DsPerformanceClass\": \"s.DsPerformanceClass\",\n",
    "    \"DsModoContrato\": \"s.DsModoContrato\",\n",
    "    \"StSaturacao\": \"s.StSaturacao\",\n",
    "    \"FlTopRestaurantes\": \"s.FlTopRestaurantes\",\n",
    "    \"DsTipoComida\": \"s.DsTipoComida\",\n",
    "    \"DsEstado\": \"s.DsEstado\",\n",
    "    \"DsCidade\": \"s.DsCidade\",\n",
    "    \"DsMaturidadeMercadoCidade\": \"s.DsMaturidadeMercadoCidade\",\n",
    "    \"TsInclusao\": \"s.TsInclusao\"\n",
    " })\n",
    " .whenNotMatchedInsert(values={\n",
    "    \"IdMerchant\": \"s.IdMerchant\",\n",
    "    \"IdSubscriber\": \"s.IdSubscriber\",\n",
    "    \"DsPerformanceClass\": \"s.DsPerformanceClass\",\n",
    "    \"DsModoContrato\": \"s.DsModoContrato\",\n",
    "    \"StSaturacao\": \"s.StSaturacao\",\n",
    "    \"FlTopRestaurantes\": \"s.FlTopRestaurantes\",\n",
    "    \"DsTipoComida\": \"s.DsTipoComida\",\n",
    "    \"DsEstado\": \"s.DsEstado\",\n",
    "    \"DsCidade\": \"s.DsCidade\",\n",
    "    \"DsMaturidadeMercadoCidade\": \"s.DsMaturidadeMercadoCidade\",\n",
    "    \"TsInclusao\": \"s.TsInclusao\"\n",
    " })\n",
    " .execute()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# %sql\n",
    "# select * from workspace.ifood_silver.TbDimMerchant\n",
    "\n",
    "\n",
    "# spark.sql(\"DROP TABLE IF EXISTS workspace.ifood_silver.TbDimMerchant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f3ab0c7-50b9-47fb-9b18-93a0e00bdf9f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TbDimMerchantClusterHist"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criação da TbDimMerchantClusterHist\n",
    "\n",
    "df_cluster_bronze = spark.read.table(\"workspace.ifood_bronze.cluster_merchant_history\")\n",
    "\n",
    "df_cluster_hist = (\n",
    "    df_cluster_bronze\n",
    "    .select(\n",
    "        F.col(\"merchant_id\").cast(StringType()).alias(\"IdMerchant\"),\n",
    "        # tenta converter coluna de data para DateType; ajustar o formato se necessário\n",
    "        F.to_date(F.col(\"reference_date\")).alias(\"DtReferencia\"),\n",
    "        F.col(\"macro_cluster_crm\").cast(StringType()).alias(\"DsCluster\"),\n",
    "        F.current_timestamp().alias(\"TsInclusao\")\n",
    "    )\n",
    "    .dropDuplicates([\"IdMerchant\",\"DtReferencia\"])\n",
    ")\n",
    "\n",
    "# aplica a limpeza de nulos textuais\n",
    "df_cluster_hist = normalize_nulls(df_cluster_hist)\n",
    "\n",
    "\n",
    "\n",
    "# Faz o merge: cria a tabela se não existir, ou atualiza se existir\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# Depois que a tabela for criada é só comentar esse bloco\n",
    "# Cria como Delta na camada Silver\n",
    "df_cluster_hist.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"workspace.ifood_silver.TbDimMerchantClusterHist\")\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Referência à tabela Silver\n",
    "delta_table = DeltaTable.forName(spark, \"workspace.ifood_silver.TbDimMerchantClusterHist\")\n",
    "\n",
    "# Merge dos dados novos\n",
    "(delta_table.alias(\"t\")\n",
    " .merge(\n",
    "     df_cluster_hist.alias(\"s\"),\n",
    "     \"t.IdMerchant = s.IdMerchant and t.DtReferencia = s.DtReferencia\"\n",
    " )\n",
    " .whenMatchedUpdate(set={\n",
    "    \"DsCluster\": \"s.DsCluster\",\n",
    "    \"TsInclusao\": \"s.TsInclusao\"\n",
    " })\n",
    " .whenNotMatchedInsert(values={\n",
    "    \"IdMerchant\": \"s.IdMerchant\",\n",
    "    \"DtReferencia\": \"s.DtReferencia\",\n",
    "    \"DsCluster\": \"s.DsCluster\",\n",
    "    \"TsInclusao\": \"s.TsInclusao\"\n",
    " })\n",
    " .execute()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %sql\n",
    "# select * from workspace.ifood_silver.TbDimMerchantClusterHist\n",
    "\n",
    "# spark.sql(\"DROP TABLE IF EXISTS workspace.ifood_silver.TbDimMerchantClusterHist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a958088-7caf-42ad-a5b3-ffd7f04d1360",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TbDimMerchantCluster"
    }
   },
   "outputs": [],
   "source": [
    "# Criação da TbDimMerchantCluster\n",
    "\n",
    "# Lê a tabela histórica\n",
    "df_hist = spark.read.table(\"workspace.ifood_silver.tbdimmerchantclusterhist\")\n",
    "\n",
    "# Cria janela para pegar a data mais recente por IdMerchant\n",
    "w = Window.partitionBy(\"IdMerchant\").orderBy(F.col(\"DtReferencia\").desc())\n",
    "\n",
    "# Marca a linha mais recente\n",
    "df_latest = (\n",
    "    df_hist\n",
    "    .withColumn(\"rank\", F.row_number().over(w))\n",
    "    .filter(F.col(\"rank\") == 1)\n",
    "    .select(\"IdMerchant\", \"DsCluster\", \"DtReferencia\", \"TsInclusao\")\n",
    ")\n",
    "\n",
    "# Grava na tabela final\n",
    "df_latest.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"workspace.ifood_silver.TbDimMerchantCluster\")\n",
    "\n",
    "\n",
    "# %sql\n",
    "# select * from workspace.ifood_silver.TbDimMerchantCluster\n",
    "\n",
    "# spark.sql(\"DROP TABLE IF EXISTS workspace.ifood_silver.TbDimMerchantCluster\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72a65c3e-9b07-4cea-bc97-313aacca5cd6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TbDimCampanha"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/expressions.py:1134: UserWarning: WARN WindowExpression: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/expressions.py:1134: UserWarning: WARN WindowExpression: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Criação da TbDimCampanha\n",
    "\n",
    "df_comm_bronze = spark.read.table(\"workspace.ifood_bronze.communications_base\")\n",
    "\n",
    "df_campanha_distinct = (\n",
    "    df_comm_bronze\n",
    "    .select(\n",
    "        F.col(\"nome_campanha\").cast(StringType()).alias(\"DsNomeCampanha\"),\n",
    "        F.col(\"categoria\").cast(StringType()).alias(\"DsCategoria\"),\n",
    "        # Tenta converter a data — se não funcionar, fica nula\n",
    "        F.try_to_timestamp(F.col(\"data_primeira_acao\")).alias(\"DtInclusao\"),\n",
    "\n",
    "        F.col(\"flag_regua\").cast(StringType()).alias(\"DsRegua\")\n",
    "    )\n",
    "    .dropDuplicates([\"DsNomeCampanha\", \"DsCategoria\"])\n",
    ")\n",
    "F.try_to_timestamp(F.col(\"data_primeira_acao\")).alias(\"DtInclusao\")\n",
    "\n",
    "# Cria janela de ordenação determinística\n",
    "w = Window.partitionBy().orderBy(\n",
    "    F.coalesce(F.col(\"DtInclusao\"), F.lit(\"1900-01-01\")).asc(),\n",
    "    F.col(\"DsNomeCampanha\").asc()\n",
    ")\n",
    "\n",
    "# Gera IdCampanha numérico e sequencial\n",
    "df_campanha = (\n",
    "    df_campanha_distinct\n",
    "    .withColumn(\"IdCampanha\", F.row_number().over(w).cast(IntegerType()))\n",
    "    .withColumn(\"TsInclusao\", F.current_timestamp())\n",
    "    .select(\"IdCampanha\", \"DsNomeCampanha\", \"DsCategoria\", \"DsRegua\",\"TsInclusao\")\n",
    "    .dropDuplicates([\"IdCampanha\"])\n",
    ")\n",
    "\n",
    "# aplica a limpeza de nulos textuais\n",
    "df_campanha = normalize_nulls(df_campanha)\n",
    "\n",
    "# Grava na camada Silver\n",
    "\n",
    "# Faz o merge: cria a tabela se não existir, ou atualiza se existir\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# Depois que a tabela for criada é só comentar esse bloco\n",
    "# Cria como Delta na camada Silver\n",
    "df_campanha.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"workspace.ifood_silver.TbDimCampanha\")\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "delta_table = DeltaTable.forName(spark, \"workspace.ifood_silver.TbDimCampanha\")\n",
    "\n",
    "(delta_table.alias(\"t\")\n",
    " .merge(\n",
    "     df_campanha.alias(\"s\"),\n",
    "     \"t.IdCampanha = s.IdCampanha\"\n",
    " )\n",
    " .whenMatchedUpdate(set={\n",
    "     \"DsNomeCampanha\": \"s.DsNomeCampanha\",\n",
    "     \"DsCategoria\": \"s.DsCategoria\",\n",
    "     \"DsRegua\": \"s.DsRegua\",\n",
    "     \"TsInclusao\": \"s.TsInclusao\"\n",
    " })\n",
    " .whenNotMatchedInsert(values={\n",
    "     \"IdCampanha\": \"s.IdCampanha\",\n",
    "     \"DsNomeCampanha\": \"s.DsNomeCampanha\",\n",
    "     \"DsCategoria\": \"s.DsCategoria\",\n",
    "     \"DsRegua\": \"s.DsRegua\",\n",
    "     \"TsInclusao\": \"s.TsInclusao\"\n",
    " })\n",
    " .execute()\n",
    ")\n",
    "\n",
    "# %sql \n",
    "# select * from workspace.ifood_silver.TbDimCampanha\n",
    "# spark.sql(\"DROP TABLE IF EXISTS workspace.ifood_silver.TbDimCampanha\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e2860e6-40d3-4e24-abc5-692752d7d239",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TbFatoDisparo"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lê comunicações brutas\n",
    "df_comm = spark.read.table(\"workspace.ifood_bronze.communications_base\")\n",
    "\n",
    "# %sql\n",
    "# select * from workspace.ifood_bronze.communications_base\n",
    "# where SubscriberKey = '1Zx8011'\n",
    "# WHERE VALUE = 2\n",
    "# \n",
    "\n",
    "# Mapeia etapas para flags e normaliza datas/canal\n",
    "df_events = (\n",
    "    df_comm\n",
    "    .withColumn(\"IdSubscriber\", F.col(\"SubscriberKey\").cast(StringType()))\n",
    "    .withColumn(\"IdDisparo\", F.col(\"BatchID\").cast(StringType()))\n",
    "    .withColumn(\"DtDisparo\", F.try_to_timestamp(F.col(\"data_primeira_acao\")))  # ajuste formato se necessário\n",
    "    .withColumn(\"DsNomeCampanha\", F.col(\"nome_campanha\").cast(StringType()))\n",
    "    .withColumn(\"DsCanal\", F.col(\"tipo_disparo\").cast(StringType()))\n",
    "    .withColumn(\"etapa\", F.col(\"etapa\").cast(StringType()))\n",
    "    .select(\"IdSubscriber\", \"IdDisparo\", \"DtDisparo\", \"DsNomeCampanha\", \"DsCanal\", \"etapa\")\n",
    ")\n",
    "\n",
    "# Agregação por subscriber + data + campanha + canal\n",
    "agg = (\n",
    "    df_events.groupBy(\"IdSubscriber\", \"IdDisparo\", \"DsNomeCampanha\", \"DsCanal\")\n",
    "    .agg(\n",
    "        F.min(\"DtDisparo\").alias(\"DtDisparo\"),\n",
    "\n",
    "        F.max(F.when(F.col(\"etapa\") == \"REQUESTED_SENT\", 1).otherwise(0)).alias(\"FlSolicitacaodisparo\"),\n",
    "        F.max(F.when(F.col(\"etapa\") == \"REQUESTED_FAILED\", 1).otherwise(0)).alias(\"FlFalhaSolicitacaodisparo\"),\n",
    "\n",
    "        F.max(F.when(F.col(\"etapa\") == \"SENT_SUCCESS\", 1).otherwise(0)).alias(\"FlDisparo\"),\n",
    "\n",
    "        F.max(F.when(F.col(\"etapa\") == \"DELIVERED_SUCCESS\", 1).otherwise(0)).alias(\"FlEntrega\"),\n",
    "        F.max(F.when(F.col(\"etapa\") == \"FAILED\", 1).otherwise(0)).alias(\"FlFalhaEntrega\"),\n",
    "\n",
    "        F.max(F.when(F.col(\"etapa\").isin(\"OPEN_SUCCESS\",\"READ_SUCCESS\"), 1).otherwise(0)).alias(\"FlAbertura\"),\n",
    "\n",
    "        F.max(F.when(F.col(\"etapa\") == \"CLICK_SUCCESS\", 1).otherwise(0)).alias(\"FlClique\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Junta com dim campanha para obter IdCampanha\n",
    "df_campanha = spark.table(\"workspace.ifood_silver.TbDimCampanha\")\n",
    "\n",
    "fato_disparo = (\n",
    "    agg.join(df_campanha, agg.DsNomeCampanha == df_campanha.DsNomeCampanha, how=\"left\")\n",
    "    .select(\n",
    "        F.col(\"IdSubscriber\").alias(\"IdSubscriber\"),\n",
    "        F.col(\"IdDisparo\").alias(\"IdDisparo\"),\n",
    "        F.col(\"DtDisparo\").alias(\"DthrDisparo\"),\n",
    "        F.to_date(col(\"DtDisparo\")).alias(\"DtDisparo\"),\n",
    "        F.col(\"IdCampanha\").cast(IntegerType()).alias(\"IdCampanha\"),\n",
    "        F.col(\"DsCanal\").cast(StringType()).alias(\"DsCanal\"),\n",
    "        F.col(\"FlSolicitacaodisparo\").cast(IntegerType()).alias(\"FlSolicitacaodisparo\"),\n",
    "        F.col(\"FlFalhaSolicitacaodisparo\").cast(IntegerType()).alias(\"FlFalhaSolicitacaodisparo\"),\n",
    "        F.col(\"FlDisparo\").cast(IntegerType()).alias(\"FlDisparo\"),\n",
    "        F.col(\"FlEntrega\").cast(IntegerType()).alias(\"FlEntrega\"),\n",
    "        F.col(\"FlFalhaEntrega\").cast(IntegerType()).alias(\"FlFalhaEntrega\"),\n",
    "        F.col(\"FlAbertura\").cast(IntegerType()).alias(\"FlAbertura\"),\n",
    "        F.col(\"FlClique\").cast(IntegerType()).alias(\"FlClique\"),\n",
    "        F.current_timestamp().alias(\"TsInclusao\")\n",
    "    )\n",
    "    .dropDuplicates([\"IdSubscriber\",\"IdDisparo\"])\n",
    ")\n",
    "\n",
    "# Grava na camada Silver\n",
    "\n",
    "# Faz o merge: cria a tabela se não existir, ou atualiza se existir\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# Depois que a tabela for criada é só comentar esse bloco\n",
    "# Cria como Delta na camada Silver\n",
    "fato_disparo.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"workspace.ifood_silver.TbFatoDisparo\")\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "delta_table = DeltaTable.forName(spark, \"workspace.ifood_silver.TbFatoDisparo\")\n",
    "\n",
    "(delta_table.alias(\"t\")\n",
    " .merge(\n",
    "     fato_disparo.alias(\"s\"),\n",
    "     \"t.IdSubscriber = s.IdSubscriber and t.IdDisparo = s.IdDisparo\"\n",
    " )\n",
    " .whenMatchedUpdate(set={\n",
    "     \"DtDisparo\": \"s.DtDisparo\",\n",
    "     \"DtDisparo\": \"s.DtDisparo\",\n",
    "     \"IdCampanha\": \"s.IdCampanha\",\n",
    "     \"DsCanal\": \"s.DsCanal\",\n",
    "     \"FlSolicitacaodisparo\": \"s.FlSolicitacaodisparo\",\n",
    "     \"FlFalhaSolicitacaodisparo\": \"s.FlFalhaSolicitacaodisparo\",\n",
    "     \"FlDisparo\": \"s.FlDisparo\",\n",
    "     \"FlEntrega\": \"s.FlEntrega\",\n",
    "     \"FlFalhaEntrega\": \"s.FlFalhaEntrega\",\n",
    "     \"FlAbertura\": \"s.FlAbertura\",\n",
    "     \"FlClique\": \"s.FlClique\",\n",
    "     \"TsInclusao\": \"s.TsInclusao\"\n",
    " })\n",
    " .whenNotMatchedInsert(values={\n",
    "     \"IdSubscriber\": \"s.IdSubscriber\",\n",
    "     \"IdDisparo\": \"s.IdDisparo\",\n",
    "     \"DtDisparo\": \"s.DtDisparo\",\n",
    "     \"DthrDisparo\": \"s.DthrDisparo\",\n",
    "     \"IdCampanha\": \"s.IdCampanha\",\n",
    "     \"DsCanal\": \"s.DsCanal\",\n",
    "     \"FlSolicitacaodisparo\": \"s.FlSolicitacaodisparo\",\n",
    "     \"FlFalhaSolicitacaodisparo\": \"s.FlFalhaSolicitacaodisparo\",\n",
    "     \"FlDisparo\": \"s.FlDisparo\",\n",
    "     \"FlEntrega\": \"s.FlEntrega\",\n",
    "     \"FlFalhaEntrega\": \"s.FlFalhaEntrega\",\n",
    "     \"FlAbertura\": \"s.FlAbertura\",\n",
    "     \"FlClique\": \"s.FlClique\",\n",
    "     \"TsInclusao\": \"s.TsInclusao\"\n",
    " })\n",
    " .execute()\n",
    ")\n",
    "\n",
    "\n",
    "# %sql\n",
    "# select * from workspace.ifood_silver.TbFatoDisparo\n",
    "# where flentrega = flfalhaentrega and flfalhaentrega = 1\n",
    "# and dscanal = 'WHATSAPP'\n",
    "\n",
    "# spark.sql(\"DROP TABLE IF EXISTS workspace.ifood_silver.TbFatoDisparo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cc21a18-f4f2-4c28-b81a-cfab953819a4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TbFatoConversao"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criação da TbFatoConversao\n",
    "\n",
    "df_conv_bronze = spark.read.table(\"workspace.ifood_bronze.conversion_base\")\n",
    "\n",
    "df_conv = (\n",
    "    df_conv_bronze\n",
    "    .select(\n",
    "        F.to_date(F.col(\"dt\")).alias(\"DtConversao\"),\n",
    "        F.col(\"SubscriberKey\").cast(StringType()).alias(\"IdSubscriber\"),\n",
    "        F.col(\"categoria\").cast(StringType()).alias(\"DsCategoria\"),\n",
    "        F.current_timestamp().alias(\"TsInclusao\")\n",
    "    )\n",
    "    .dropDuplicates([\"DtConversao\",\"IdSubscriber\",\"DsCategoria\"])\n",
    ")\n",
    "\n",
    "# aplica a limpeza de nulos textuais\n",
    "df_conv = normalize_nulls(df_conv)\n",
    "\n",
    "df_conv.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"workspace.ifood_silver.TbFatoConversao\")\n",
    "\n",
    "\n",
    "\n",
    "# Grava na camada Silver\n",
    "\n",
    "# Faz o merge: cria a tabela se não existir, ou atualiza se existir\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# Depois que a tabela for criada é só comentar esse bloco\n",
    "# Cria como Delta na camada Silver\n",
    "df_conv.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"workspace.ifood_silver.TbFatoConversao\")\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "delta_table = DeltaTable.forName(spark, \"workspace.ifood_silver.TbFatoConversao\")\n",
    "\n",
    "(delta_table.alias(\"t\")\n",
    " .merge(\n",
    "     df_conv.alias(\"s\"),\n",
    "     \"t.IdSubscriber = s.IdSubscriber and t.DtConversao = s.DtConversao and t.DsCategoria = s.DsCategoria\"\n",
    " )\n",
    " .whenMatchedUpdate(set={\n",
    "     \"TsInclusao\": \"s.TsInclusao\"\n",
    " })\n",
    " .whenNotMatchedInsert(values={\n",
    "     \"DtConversao\": \"s.DtConversao\",\n",
    "     \"IdSubscriber\": \"s.IdSubscriber\",\n",
    "     \"DsCategoria\": \"s.DsCategoria\",\n",
    "     \"TsInclusao\": \"s.TsInclusao\"\n",
    " })\n",
    " .execute()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# %sql \n",
    "# select * from workspace.ifood_silver.TbFatoConversao\n",
    "\n",
    "# spark.sql(\"DROP TABLE IF EXISTS workspace.ifood_silver.TbFatoConversao\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a7b1ecd-4950-41f2-b453-fc0e6a44eb6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Camada Gold\n",
    "\n",
    "Criação das Tabelas Consolidadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5191673c-4bdf-44f3-9771-cb6dab23193d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TbVisãoCampanhaMensal"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "num_affected_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_inserted_rows",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 34
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- # Criação da TbVisãoCampanhaMensal\n",
    "-- %sql\n",
    "\n",
    "CREATE OR REPLACE TABLE workspace.ifood_gold.TbVisaoCampanhaMensal AS \n",
    "\n",
    "select distinct\n",
    "\n",
    "    year(to_date(dtdisparo)) as ano,\n",
    "    month(to_date(dtdisparo)) as mes, \n",
    "    a.IdCampanha, \n",
    "    b.DsNomeCampanha,\n",
    "    b.DsCategoria,\n",
    "    b.DsRegua,\n",
    "    DsCanal,\n",
    "    count(distinct case when FlSolicitacaoDisparo = 1 then a.idsubscriber end) as QtSolicitacaoDisparo,\n",
    "    count(distinct case when FlFalhaSolicitacaoDisparo = 1 then a.idsubscriber end) as QtFalhaSolicitacaoDisparo,\n",
    "    count(distinct case when FlDisparo = 1 then a.idsubscriber end) as QtDisparo,\n",
    "    count(distinct case when FlEntrega = 1 then a.idsubscriber end) as QtEntrega,\n",
    "    count(distinct case when FlFalhaEntrega = 1 then a.idsubscriber end) as QtFalhaEntrega,\n",
    "    count(distinct case when FlAbertura = 1 then a.idsubscriber end) as QtAbertura,\n",
    "    count(distinct case when FlClique = 1 then a.idsubscriber end) as QtClique,\n",
    "    count(distinct case when datediff(c.DtConversao, a.DtDisparo)<=7 then c.idsubscriber end) as QtConversao7Dias,\n",
    "    count(distinct case when datediff(c.DtConversao, a.DtDisparo)<=15 then c.idsubscriber end) as QtConversao15Dias,\n",
    "    count(distinct case when datediff(c.DtConversao, a.DtDisparo)<=30 then c.idsubscriber end) as QtConversao30Dias\n",
    "\n",
    "from workspace.ifood_silver.TbFatoDisparo as a\n",
    "left join workspace.ifood_silver.TbDimCampanha as b\n",
    "    on a.IdCampanha = b.IdCampanha\n",
    "left join workspace.ifood_silver.TbFatoConversao as c\n",
    "    on a.IdSubscriber = c.IdSubscriber and b.DsCategoria = c.DsCategoria and datediff(c.DtConversao, a.DtDisparo) between 0 and 30\n",
    "group by \n",
    "    year(to_date(dtdisparo)),\n",
    "    month(to_date(dtdisparo)),\n",
    "    a.IdCampanha, \n",
    "    b.DsNomeCampanha,\n",
    "    b.DsCategoria,\n",
    "    b.DsRegua,\n",
    "    DsCanal\n",
    "\n",
    "-- %sql select * from workspace.ifood_gold.TbVisaoCampanhaMensal\n",
    "-- spark.sql(\"DROP TABLE IF EXISTS workspace.ifood_silver.TbVisaoCampanhaMensal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1e95644-8b07-4881-a257-5e0888331a43",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TbVisaoCampanhaDiaria"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "num_affected_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_inserted_rows",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 35
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- # Criação da TbVisãoCampanhaDiaria\n",
    "-- %sql\n",
    "\n",
    "CREATE OR REPLACE TABLE workspace.ifood_gold.TbVisaoCampanhaDiaria AS \n",
    "\n",
    "select distinct\n",
    "\n",
    "    dtdisparo as DtDisparo, \n",
    "    a.IdCampanha, \n",
    "    b.DsNomeCampanha,\n",
    "    b.DsCategoria,\n",
    "    b.DsRegua,\n",
    "    DsCanal,\n",
    "    count(distinct case when FlSolicitacaoDisparo = 1 then a.idsubscriber end) as QtSolicitacaoDisparo,\n",
    "    count(distinct case when FlFalhaSolicitacaoDisparo = 1 then a.idsubscriber end) as QtFalhaSolicitacaoDisparo,\n",
    "    count(distinct case when FlDisparo = 1 then a.idsubscriber end) as QtDisparo,\n",
    "    count(distinct case when FlEntrega = 1 then a.idsubscriber end) as QtEntrega,\n",
    "    count(distinct case when FlFalhaEntrega = 1 then a.idsubscriber end) as QtFalhaEntrega,\n",
    "    count(distinct case when FlAbertura = 1 then a.idsubscriber end) as QtAbertura,\n",
    "    count(distinct case when FlClique = 1 then a.idsubscriber end) as QtClique,\n",
    "    count(distinct case when datediff(c.DtConversao, a.DtDisparo)<=7 then c.idsubscriber end) as QtConversao7Dias,\n",
    "    count(distinct case when datediff(c.DtConversao, a.DtDisparo)<=15 then c.idsubscriber end) as QtConversao15Dias,\n",
    "    count(distinct case when datediff(c.DtConversao, a.DtDisparo)<=30 then c.idsubscriber end) as QtConversao30Dias\n",
    "\n",
    "from workspace.ifood_silver.TbFatoDisparo as a\n",
    "left join workspace.ifood_silver.TbDimCampanha as b\n",
    "    on a.IdCampanha = b.IdCampanha\n",
    "left join workspace.ifood_silver.TbFatoConversao as c\n",
    "    on a.IdSubscriber = c.IdSubscriber and b.DsCategoria = c.DsCategoria and datediff(c.DtConversao, a.DtDisparo) between 0 and 30\n",
    "group by \n",
    "    dtdisparo,\n",
    "    a.IdCampanha, \n",
    "    b.DsNomeCampanha,\n",
    "    b.DsCategoria,\n",
    "    b.DsRegua,\n",
    "    DsCanal\n",
    "\n",
    "-- %sql select * from workspace.ifood_gold.TbVisaoCampanhaDiaria\n",
    "-- spark.sql(\"DROP TABLE IF EXISTS workspace.ifood_silver.TbVisaoCampanhaDiaria\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa77b9ed-5a95-4f8f-9aa0-7eae313f4aa7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TbVisaoMerchantMensal"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "num_affected_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_inserted_rows",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 36
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- # Criação da TbVisaoMerchantMensal\n",
    "-- %sql\n",
    "\n",
    "CREATE OR REPLACE TABLE workspace.ifood_gold.TbVisaoMerchantMensal AS \n",
    "\n",
    "select distinct\n",
    "\n",
    "    year(to_date(a.dtdisparo)) as ano,\n",
    "    month(to_date(a.dtdisparo)) as mes, \n",
    "    a.IdCampanha, \n",
    "    b.DsNomeCampanha,\n",
    "    b.DsCategoria,\n",
    "    b.DsRegua,\n",
    "    a.DsCanal,\n",
    "    d.DsCidade,\n",
    "    d.DsEstado,\n",
    "    d.DsMaturidadeMercadoCidade,\n",
    "    d.DsModoContrato,\n",
    "    d.DsPerformanceClass,\n",
    "    d.StSaturacao,\n",
    "    d.FlTopRestaurantes,\n",
    "    d.DsTipoComida,\n",
    "    e.DsCluster,\n",
    "    count(distinct case when FlSolicitacaoDisparo = 1 then a.idsubscriber end) as QtSolicitacaoDisparo,\n",
    "    count(distinct case when FlFalhaSolicitacaoDisparo = 1 then a.idsubscriber end) as QtFalhaSolicitacaoDisparo,\n",
    "    count(distinct case when FlDisparo = 1 then a.idsubscriber end) as QtDisparo,\n",
    "    count(distinct case when FlEntrega = 1 then a.idsubscriber end) as QtEntrega,\n",
    "    count(distinct case when FlFalhaEntrega = 1 then a.idsubscriber end) as QtFalhaEntrega,\n",
    "    count(distinct case when FlAbertura = 1 then a.idsubscriber end) as QtAbertura,\n",
    "    count(distinct case when FlClique = 1 then a.idsubscriber end) as QtClique,\n",
    "    count(distinct case when datediff(c.DtConversao, a.DtDisparo)<=7 then c.idsubscriber end) as QtConversao7Dias,\n",
    "    count(distinct case when datediff(c.DtConversao, a.DtDisparo)<=15 then c.idsubscriber end) as QtConversao15Dias,\n",
    "    count(distinct case when datediff(c.DtConversao, a.DtDisparo)<=30 then c.idsubscriber end) as QtConversao30Dias\n",
    "\n",
    "from workspace.ifood_silver.TbFatoDisparo as a\n",
    "left join workspace.ifood_silver.TbDimCampanha as b\n",
    "    on a.IdCampanha = b.IdCampanha\n",
    "left join workspace.ifood_silver.TbFatoConversao as c\n",
    "    on a.IdSubscriber = c.IdSubscriber and b.DsCategoria = c.DsCategoria and datediff(c.DtConversao, a.DtDisparo) between 0 and 30\n",
    "left join workspace.ifood_silver.TbDimMerchant as d\n",
    "    on a.IdSubscriber = d.IdSubscriber\n",
    "left join workspace.ifood_silver.TbDimMerchantCluster as e\n",
    "    on d.IdMerchant = e.IdMerchant\n",
    "\n",
    "group by \n",
    "    year(to_date(dtdisparo)),\n",
    "    month(to_date(dtdisparo)),\n",
    "    a.IdCampanha, \n",
    "    b.DsNomeCampanha,\n",
    "    b.DsCategoria,\n",
    "    b.DsRegua,\n",
    "    a.DsCanal,\n",
    "    d.DsCidade,\n",
    "    d.DsEstado,\n",
    "    d.DsMaturidadeMercadoCidade,\n",
    "    d.DsModoContrato,\n",
    "    d.DsPerformanceClass,\n",
    "    d.StSaturacao,\n",
    "    d.FlTopRestaurantes,\n",
    "    d.DsTipoComida,\n",
    "    e.DsCluster\n",
    "\n",
    "-- %sql select count(*) from workspace.ifood_gold.TbVisaoMerchantMensal\n",
    "-- %sql select count(*) from workspace.ifood_silver.TbFatoDisparo\n",
    "-- spark.sql(\"DROP TABLE IF EXISTS workspace.ifood_silver.TbVisaoMerchantMensal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f307aed6-db2c-4294-98f3-5e92e42a8187",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TbVisaoMerchantDiaria"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "num_affected_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_inserted_rows",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 37
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- # Criação da TbVisaoMerchantDiaria\n",
    "-- %sql\n",
    "\n",
    "CREATE OR REPLACE TABLE workspace.ifood_gold.TbVisaoMerchantDiaria AS \n",
    "\n",
    "select distinct\n",
    "\n",
    "    a.DtDisparo,\n",
    "    a.IdCampanha, \n",
    "    b.DsNomeCampanha,\n",
    "    b.DsCategoria,\n",
    "    b.DsRegua,\n",
    "    a.DsCanal,\n",
    "    d.DsCidade,\n",
    "    d.DsEstado,\n",
    "    d.DsMaturidadeMercadoCidade,\n",
    "    d.DsModoContrato,\n",
    "    d.DsPerformanceClass,\n",
    "    d.StSaturacao,\n",
    "    d.FlTopRestaurantes,\n",
    "    d.DsTipoComida,\n",
    "    e.DsCluster,\n",
    "    count(distinct case when FlSolicitacaoDisparo = 1 then a.idsubscriber end) as QtSolicitacaoDisparo,\n",
    "    count(distinct case when FlFalhaSolicitacaoDisparo = 1 then a.idsubscriber end) as QtFalhaSolicitacaoDisparo,\n",
    "    count(distinct case when FlDisparo = 1 then a.idsubscriber end) as QtDisparo,\n",
    "    count(distinct case when FlEntrega = 1 then a.idsubscriber end) as QtEntrega,\n",
    "    count(distinct case when FlFalhaEntrega = 1 then a.idsubscriber end) as QtFalhaEntrega,\n",
    "    count(distinct case when FlAbertura = 1 then a.idsubscriber end) as QtAbertura,\n",
    "    count(distinct case when FlClique = 1 then a.idsubscriber end) as QtClique,\n",
    "    count(distinct case when datediff(c.DtConversao, a.DtDisparo)<=7 then c.idsubscriber end) as QtConversao7Dias,\n",
    "    count(distinct case when datediff(c.DtConversao, a.DtDisparo)<=15 then c.idsubscriber end) as QtConversao15Dias,\n",
    "    count(distinct case when datediff(c.DtConversao, a.DtDisparo)<=30 then c.idsubscriber end) as QtConversao30Dias\n",
    "\n",
    "from workspace.ifood_silver.TbFatoDisparo as a\n",
    "left join workspace.ifood_silver.TbDimCampanha as b\n",
    "    on a.IdCampanha = b.IdCampanha\n",
    "left join workspace.ifood_silver.TbFatoConversao as c\n",
    "    on a.IdSubscriber = c.IdSubscriber and b.DsCategoria = c.DsCategoria and datediff(c.DtConversao, a.DtDisparo) between 0 and 30\n",
    "left join workspace.ifood_silver.TbDimMerchant as d\n",
    "    on a.IdSubscriber = d.IdSubscriber\n",
    "left join workspace.ifood_silver.TbDimMerchantCluster as e\n",
    "    on d.IdMerchant = e.IdMerchant\n",
    "\n",
    "group by \n",
    "    a.DtDisparo,\n",
    "    a.IdCampanha, \n",
    "    b.DsNomeCampanha,\n",
    "    b.DsCategoria,\n",
    "    b.DsRegua,\n",
    "    a.DsCanal,\n",
    "    d.DsCidade,\n",
    "    d.DsEstado,\n",
    "    d.DsMaturidadeMercadoCidade,\n",
    "    d.DsModoContrato,\n",
    "    d.DsPerformanceClass,\n",
    "    d.StSaturacao,\n",
    "    d.FlTopRestaurantes,\n",
    "    d.DsTipoComida,\n",
    "    e.DsCluster\n",
    "\n",
    "-- %sql select count(*) from workspace.ifood_gold.TbVisaoMerchantDiaria\n",
    "-- %sql select count(*) from workspace.ifood_silver.TbFatoDisparo\n",
    "-- spark.sql(\"DROP TABLE IF EXISTS workspace.ifood_silver.TbVisaoMerchantDiaria\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8103726957802910,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "etl_modelagem_case_ifood",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}